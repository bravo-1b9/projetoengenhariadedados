version: '3.8' # Adicionar a versão é uma boa prática

services:
  app: # Nome do nosso servico de aplicacao Python
    build: ./app # Instrui o Compose a construir a imagem a partir do Dockerfile em ./app
    depends_on:
      - dbpg # Garante que o servico 'db' seja iniciado antes do 'app'
    environment: # Variaveis de ambiente para o container 'app'
      - DB_HOST=dbpg # O host é o nome do serviço do banco de dados
      - DB_NAME=${DB_NAME:-mydatabase} # Usa valor do .env ou default
      - DB_USER=${DB_USER:-user}
      - DB_PASSWORD=${DB_PASSWORD:-password}
    networks:
      - app-network

  dbpg: # Nome do nosso servico de banco de dados PostgreSQL
    image: postgres:13-alpine # Usa uma imagem oficial do PostgreSQL (versao Alpine e menor)
    environment: # Variaveis de ambiente para configurar o PostgreSQL
      # Valores fixos para garantir a criação
      - POSTGRES_DB=mydatabase
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data # Persiste os dados do PostgreSQL
    ports:
      - "5433:5432" # Mapeia a porta 5432 do container para a 5433 do host
    networks:
      - app-network

  dbt:
    build: ./dbt 
    depends_on:
      - dbpg 
    volumes:
      - ./dbt/projeto_dbt:/usr/app/dbt/projeto_dbt
    environment: 
      - DB_HOST=dbpg 
      - DB_PORT=5432 
      - DB_NAME=mydatabase
      - DB_USER=user
      - DB_PASSWORD=password
      - DB_SCHEMA=public
    command: >
      sh -c "
        dbt deps &&
        dbt seed &&
        dbt run
      "
    networks:
      - app-network

  # O serviço do Spark permanece o mesmo, pois é opcional.
  dbt-spark3-thrift:
    build:
      context: ./spark
      dockerfile: spark.Dockerfile
    ports:
      - "10000:10000"
      - "4040:4040"
    depends_on:
      - dbpg
    command: >
      --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2
      --name Thrift JDBC/ODBC Server
    volumes:
      - ./.spark-warehouse/:/spark-warehouse/
      - ./docker/hive-site.xml:/usr/spark/conf/hive-site.xml
      - ./docker/spark-defaults.conf:/usr/spark/conf/spark-defaults.conf
    environment:
      - WAIT_FOR=dbpg:5432      
    networks:
      - app-network

volumes:
  postgres_data: # Define um volume nomeado para persistencia dos dados do DB

networks:
  app-network: # Define uma rede customizada do tipo bridge
    driver: bridge